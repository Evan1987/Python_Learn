{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return matrix shape m*n：m-样本数，n-特征数\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = list(map(float, curLine))\n",
    "        dataMat.append(fltLine)\n",
    "    return np.mat(dataMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用欧式距离计算向量间的距离\n",
    "# return double\n",
    "def distEclud(vecA, vecB):\n",
    "    dist = np.sum(np.power(vecA-vecB,2))**0.5\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机生成簇质点\n",
    "# return matrix shape k*n：k-质点数，n-特征数\n",
    "def randCent(dataSet, k):\n",
    "    # 数据集的维数\n",
    "    n = np.shape(dataSet)[1]\n",
    "    # 生成多组 k*n 的随机组合，便于之后生成簇质点\n",
    "    # 用 set来当容器，方便保证组合没有重复\n",
    "    rand = set()\n",
    "    while len(rand)<k:\n",
    "        rand.add(tuple([random.random() for _ in range(n)]))\n",
    "    randMat = np.mat(list(map(list,list(rand))))\n",
    "    # 各维度的统计性数据\n",
    "    minMat = np.apply_along_axis(arr=dataSet, axis=0, func1d=np.min)\n",
    "    maxMat = np.apply_along_axis(arr=dataSet, axis=0, func1d=np.max)\n",
    "    rangeMat = maxMat - minMat\n",
    "    \n",
    "    centroids = minMat + np.multiply(randMat, rangeMat)\n",
    "    return centroids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k, distFun=distEclud, createCentFun=randCent):\n",
    "    centroids = createCentFun(dataSet, k)\n",
    "    totalSSE = changeSSE = np.inf    \n",
    "    # 给出每个样本最近的簇质点序号以及 SE\n",
    "    # return (index:Int, dist^2:Double)\n",
    "    def getIndex(vecA, centroids, distFun):\n",
    "        distEval = np.array([distFun(vecA, x) for x in centroids])\n",
    "        index = distEval.argmin()\n",
    "        dist = distEval[index]\n",
    "        return index,dist**2\n",
    "    \n",
    "    # 根据生成的簇，计算新的簇质心\n",
    "    # return matrix shape k*n: k-质点数，n-特征数\n",
    "    def generateNewCentroids(dataSet, index, k):\n",
    "        newCentroids = np.mat([np.apply_along_axis(\n",
    "                               arr = dataSet[index==i],\n",
    "                               axis = 0,\n",
    "                               func1d=np.mean) for i in range(k)])\n",
    "        return newCentroids\n",
    "        \n",
    "    # 收敛条件：改变的 SSE≤1\n",
    "    while changeSSE>1:\n",
    "        clusterAssment = np.mat([getIndex(x, centroids,distFun) for x in dataSet])\n",
    "        index = clusterAssment[:,0].A1\n",
    "        sse = np.sum(clusterAssment[:,1])\n",
    "        changeSSE = totalSSE - sse\n",
    "        print(\"now SSE is:\", sse, \"\\t\", \"change SSE is:\", changeSSE)\n",
    "        totalSSE = sse\n",
    "        centroids = generateNewCentroids(dataSet, index, k)\n",
    "    \n",
    "    return centroids, clusterAssment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"F:/for learn/MLiA/Ch10/\"\n",
    "fileName = path + \"testSet.txt\"\n",
    "dataSet = loadDataSet(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now SSE is: 584.23021039 \t change SSE is: inf\n",
      "now SSE is: 131.213738755 \t change SSE is: 453.016471636\n",
      "now SSE is: 126.296772733 \t change SSE is: 4.91696602162\n",
      "now SSE is: 126.005036979 \t change SSE is: 0.291735754495\n"
     ]
    }
   ],
   "source": [
    "result = kMeans(dataSet, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二分K-均值聚类算法\n",
    "def biKmeans(dataSet, k, distFun=distEclud):\n",
    "    m = dataSet.shape[0]\n",
    "    # 最开始将所有数据看成是一个簇，初始化簇类别（0）和距离矩阵 clusterAssment\n",
    "    centroids = np.mean(dataSet, axis=0)\n",
    "    clusterAssment = np.mat([(0,distFun(x, centroids)) for x in dataSet])\n",
    "    while centroids.shape[0] < k:\n",
    "        lowestSSE = np.inf\n",
    "        # 遍历当前所有簇，比较从任意簇进行 2元分裂减少的 SSE\n",
    "        for i in range(centroids.shape[0]):\n",
    "            ptsInCurrCluster = dataSet[clusterAssment[:,0].A1 == i]\n",
    "            newCentroids, splitClustAss = kMeans(ptsInCurrCluster, 2, distFun)\n",
    "            # 不属于该簇的 SSE\n",
    "            sseNotSplit = np.sum(dataSet[clusterAssment[:,0].A1 != i])\n",
    "            # 该簇分裂之后的 SSE\n",
    "            sseSplit = np.sum(splitClustAss[:,1])\n",
    "            # 总的 SSE\n",
    "            totalSSE = sseNotSplit + sseSplit\n",
    "            # 若满足条件则更新一系列操作，最终遍历所有簇之后，得到最佳的分裂簇\n",
    "            if totalSSE < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = newCentroids\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = totalSSE\n",
    "        # 更新待分裂簇分裂后的簇标签（默认都是0,1，要更改成全局的标签）\n",
    "        # 0 -> i\n",
    "        # 1 -> new(centroids.shape[0])\n",
    "        bestClustAss[bestClustAss[:,0].A1 == 1,0] = centroids.shape[0]\n",
    "        bestClustAss[bestClustAss[:,0].A1 == 0,0] = bestCentToSplit\n",
    "        # 将处理好的待分裂簇数据更新到全体数据上\n",
    "        clusterAssment[clusterAssment[:,0].A1 == bestCentToSplit, :] = bestClustAss\n",
    "        # 更新并添加簇质心矩阵\n",
    "        centroids[bestCentToSplit,:] = bestNewCents[0,:]\n",
    "        centroids = np.row_stack((centroids, bestNewCents[1,:]))\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataSet2 = loadDataSet(path+\"testSet2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now SSE is: 1118.37861663 \t change SSE is: inf\n",
      "now SSE is: 470.408531369 \t change SSE is: 647.970085264\n",
      "now SSE is: 453.033489581 \t change SSE is: 17.3750417878\n",
      "now SSE is: 453.033489581 \t change SSE is: 0.0\n",
      "now SSE is: 20.0947171581 \t change SSE is: inf\n",
      "now SSE is: 13.6122231662 \t change SSE is: 6.48249399185\n",
      "now SSE is: 13.2735688138 \t change SSE is: 0.338654352448\n",
      "now SSE is: 472.719534304 \t change SSE is: inf\n",
      "now SSE is: 79.6981117038 \t change SSE is: 393.0214226\n",
      "now SSE is: 77.5922493178 \t change SSE is: 2.1058623861\n",
      "now SSE is: 77.5922493178 \t change SSE is: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(matrix([[-0.45965615, -2.7782156 ],\n",
       "         [ 2.93386365,  3.12782785],\n",
       "         [-2.94737575,  3.3263781 ]]),\n",
       " matrix([[  1.00000000e+00,   1.45461050e-01],\n",
       "         [  2.00000000e+00,   6.80213825e-01],\n",
       "         [  0.00000000e+00,   1.02184582e+00],\n",
       "         [  1.00000000e+00,   1.34548760e+00],\n",
       "         [  2.00000000e+00,   1.35376464e+00],\n",
       "         [  0.00000000e+00,   3.87167519e+00],\n",
       "         [  1.00000000e+00,   8.37259951e-01],\n",
       "         [  2.00000000e+00,   2.20116272e-01],\n",
       "         [  0.00000000e+00,   3.53809057e+00],\n",
       "         [  1.00000000e+00,   7.44081160e+00],\n",
       "         [  2.00000000e+00,   5.28070040e+00],\n",
       "         [  0.00000000e+00,   2.56674394e-02],\n",
       "         [  1.00000000e+00,   1.11946529e+00],\n",
       "         [  2.00000000e+00,   1.67890884e-01],\n",
       "         [  0.00000000e+00,   2.11734245e+00],\n",
       "         [  1.00000000e+00,   1.49635209e+00],\n",
       "         [  2.00000000e+00,   4.93628241e+00],\n",
       "         [  0.00000000e+00,   9.76749869e-03],\n",
       "         [  1.00000000e+00,   1.32453845e-01],\n",
       "         [  2.00000000e+00,   6.39346045e-01],\n",
       "         [  0.00000000e+00,   9.41791924e-01],\n",
       "         [  1.00000000e+00,   1.72445523e+00],\n",
       "         [  2.00000000e+00,   7.50682798e-01],\n",
       "         [  0.00000000e+00,   1.48785604e-01],\n",
       "         [  1.00000000e+00,   3.00429548e+00],\n",
       "         [  2.00000000e+00,   5.15437527e+00],\n",
       "         [  0.00000000e+00,   1.80316434e+00],\n",
       "         [  1.00000000e+00,   2.74825782e+00],\n",
       "         [  2.00000000e+00,   4.66860313e-01],\n",
       "         [  0.00000000e+00,   1.28807718e+00],\n",
       "         [  1.00000000e+00,   1.76804356e+00],\n",
       "         [  2.00000000e+00,   3.54002368e+00],\n",
       "         [  0.00000000e+00,   2.12516750e+00],\n",
       "         [  1.00000000e+00,   1.14812052e+00],\n",
       "         [  2.00000000e+00,   1.78247878e+00],\n",
       "         [  0.00000000e+00,   8.79445646e-01],\n",
       "         [  1.00000000e+00,   3.23315472e+00],\n",
       "         [  2.00000000e+00,   7.43934371e-01],\n",
       "         [  0.00000000e+00,   2.36276631e+00],\n",
       "         [  1.00000000e+00,   2.59370616e-01],\n",
       "         [  2.00000000e+00,   1.82015977e+00],\n",
       "         [  0.00000000e+00,   2.10599050e+00],\n",
       "         [  1.00000000e+00,   2.94567602e+00],\n",
       "         [  2.00000000e+00,   2.49952822e+00],\n",
       "         [  0.00000000e+00,   1.54957269e+00],\n",
       "         [  1.00000000e+00,   9.45169633e-01],\n",
       "         [  2.00000000e+00,   2.91966903e+00],\n",
       "         [  0.00000000e+00,   1.13851139e+00],\n",
       "         [  1.00000000e+00,   5.09476462e+00],\n",
       "         [  2.00000000e+00,   1.64971118e+00],\n",
       "         [  0.00000000e+00,   1.98934951e-01],\n",
       "         [  1.00000000e+00,   1.50301593e+00],\n",
       "         [  2.00000000e+00,   2.13359760e-01],\n",
       "         [  0.00000000e+00,   2.16005416e+00],\n",
       "         [  1.00000000e+00,   2.63462894e+00],\n",
       "         [  2.00000000e+00,   7.60898177e-02],\n",
       "         [  0.00000000e+00,   2.60198288e-01],\n",
       "         [  1.00000000e+00,   3.05416591e-03],\n",
       "         [  2.00000000e+00,   3.16776316e+00],\n",
       "         [  0.00000000e+00,   1.61040000e+00]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biKmeans(dataSet2, k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
